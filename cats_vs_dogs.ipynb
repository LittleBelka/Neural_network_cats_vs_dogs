{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!echo password_on_your_computer | sudo -S pip3 install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!echo password_on_your_computer | sudo -S pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", type=str, default='.', help=\"path to input dataset\")\n",
    "\n",
    "args = ap.parse_args([\"-d\", \"dataset\"])\n",
    "args =  vars(args)\n",
    "args[\"dataset\"] = \"data/train\"\n",
    "args[\"dataset\"]\n",
    "# args = vars(ap.parse_args())\n",
    " \n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] describing images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    " \n",
    "# initialize the data matrix and labels list\n",
    "dataTmp = []\n",
    "labelsTmp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/25000\n",
      "[INFO] processed 2000/25000\n",
      "[INFO] processed 3000/25000\n",
      "[INFO] processed 4000/25000\n",
      "[INFO] processed 5000/25000\n",
      "[INFO] processed 6000/25000\n",
      "[INFO] processed 7000/25000\n",
      "[INFO] processed 8000/25000\n",
      "[INFO] processed 9000/25000\n",
      "[INFO] processed 10000/25000\n",
      "[INFO] processed 11000/25000\n",
      "[INFO] processed 12000/25000\n",
      "[INFO] processed 13000/25000\n",
      "[INFO] processed 14000/25000\n",
      "[INFO] processed 15000/25000\n",
      "[INFO] processed 16000/25000\n",
      "[INFO] processed 17000/25000\n",
      "[INFO] processed 18000/25000\n",
      "[INFO] processed 19000/25000\n",
      "[INFO] processed 20000/25000\n",
      "[INFO] processed 21000/25000\n",
      "[INFO] processed 22000/25000\n",
      "[INFO] processed 23000/25000\n",
      "[INFO] processed 24000/25000\n"
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # load the image and extract the class label (assuming that our\n",
    "    # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "    image = cv2.imread(imagePath)\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    " \n",
    "    # construct a feature vector raw pixel intensities, then update\n",
    "    # the data matrix and labels list\n",
    "    features = image_to_feature_vector(image)\n",
    "    dataTmp.append(features)\n",
    "    labelsTmp.append(label)\n",
    " \n",
    "    # show an update every 1,000 images\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "# encode the labels, converting them from strings to integers\n",
    "labels = labelsTmp\n",
    "data = dataTmp\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    " \n",
    "# scale the input image pixels to the range [0, 1], then transform\n",
    "# the labels into vectors in the range [0, num_classes] -- this\n",
    "# generates a vector for each label where the index of the label\n",
    "# is set to `1` and all other entries to `0`\n",
    "data = np.array(data) / 255.0\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    " \n",
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "print(\"[INFO] constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split\\\n",
    "                    (data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the architecture of the network\n",
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=3072, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(384, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using SGD\n",
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "model.fit(trainData, trainLabels, nb_epoch=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating on testing set...\n",
      "6016/6250 [===========================>..] - ETA: 0s[INFO] loss=0.5990, accuracy: 68.1920%\n"
     ]
    }
   ],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you wanna save model in file, you'll need to install h5py library\n",
    "# But after this you'll need reboot you jupyter. In order to avoid it,\n",
    "# you have to just reload your keras.model (just uncomment 3 lines of \n",
    "# code below). And only after this you can save model correct.\n",
    "# Of course, if you installed h5py earlier, you don't need to uncomment\n",
    "# this code.\n",
    "\n",
    "# import keras\n",
    "# from importlib import reload\n",
    "# reload(keras.models)\n",
    "\n",
    "# save model in file\n",
    "model.save(\"cats_vs_dogs_model.h5\")\n",
    "\n",
    "\n",
    "# returns a compiled model\n",
    "#model = load_model('cats_vs_dogs_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
