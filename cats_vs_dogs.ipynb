{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import h5py\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!echo password_on_your_computer | sudo -S pip3 install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!echo password_on_your_computer | sudo -S pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] describing images...\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", type=str, default='.', help=\"path to input dataset\")\n",
    "\n",
    "args = ap.parse_args([\"-d\", \"dataset\"])\n",
    "args =  vars(args)\n",
    "args[\"dataset\"] = \"data/train\"\n",
    "args[\"dataset\"]\n",
    "# args = vars(ap.parse_args())\n",
    " \n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] describing images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    " \n",
    "# initialize the data matrix and labels list\n",
    "dataTmp = []\n",
    "labelsTmp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/25000\n",
      "[INFO] processed 2000/25000\n",
      "[INFO] processed 3000/25000\n",
      "[INFO] processed 4000/25000\n",
      "[INFO] processed 5000/25000\n",
      "[INFO] processed 6000/25000\n",
      "[INFO] processed 7000/25000\n",
      "[INFO] processed 8000/25000\n",
      "[INFO] processed 9000/25000\n",
      "[INFO] processed 10000/25000\n",
      "[INFO] processed 11000/25000\n",
      "[INFO] processed 12000/25000\n",
      "[INFO] processed 13000/25000\n",
      "[INFO] processed 14000/25000\n",
      "[INFO] processed 15000/25000\n",
      "[INFO] processed 16000/25000\n",
      "[INFO] processed 17000/25000\n",
      "[INFO] processed 18000/25000\n",
      "[INFO] processed 19000/25000\n",
      "[INFO] processed 20000/25000\n",
      "[INFO] processed 21000/25000\n",
      "[INFO] processed 22000/25000\n",
      "[INFO] processed 23000/25000\n",
      "[INFO] processed 24000/25000\n"
     ]
    }
   ],
   "source": [
    "# loop over the input images\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # load the image and extract the class label (assuming that our\n",
    "    # path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
    "    image = cv2.imread(imagePath)\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    " \n",
    "    # construct a feature vector raw pixel intensities, then update\n",
    "    # the data matrix and labels list\n",
    "    features = image_to_feature_vector(image)\n",
    "    dataTmp.append(features)\n",
    "    labelsTmp.append(label)\n",
    " \n",
    "    # show an update every 1,000 images\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(\"[INFO] processed {}/{}\".format(i, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] constructing training/testing split...\n"
     ]
    }
   ],
   "source": [
    "# encode the labels, converting them from strings to integers\n",
    "labels = labelsTmp\n",
    "data = dataTmp\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    " \n",
    "# scale the input image pixels to the range [0, 1], then transform\n",
    "# the labels into vectors in the range [0, num_classes] -- this\n",
    "# generates a vector for each label where the index of the label\n",
    "# is set to `1` and all other entries to `0`\n",
    "data = np.array(data) / 255.0\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    " \n",
    "# partition the data into training and testing splits, using 75%\n",
    "# of the data for training and the remaining 25% for testing\n",
    "print(\"[INFO] constructing training/testing split...\")\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split\\\n",
    "                    (data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlebelka/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(768, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=3072)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/littlebelka/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(384, kernel_initializer=\"uniform\", activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# define the architecture of the network\n",
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=3072, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(384, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18750/18750 [==============================] - 14s - loss: 0.6823 - acc: 0.5714    \n",
      "Epoch 2/50\n",
      "18750/18750 [==============================] - 10s - loss: 0.6620 - acc: 0.6056    \n",
      "Epoch 3/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6521 - acc: 0.6151     \n",
      "Epoch 4/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6483 - acc: 0.6207     \n",
      "Epoch 5/50\n",
      "18750/18750 [==============================] - 8s - loss: 0.6401 - acc: 0.6357     \n",
      "Epoch 6/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6356 - acc: 0.6391     \n",
      "Epoch 7/50\n",
      "18750/18750 [==============================] - 8s - loss: 0.6297 - acc: 0.6435     \n",
      "Epoch 8/50\n",
      "18750/18750 [==============================] - 10s - loss: 0.6284 - acc: 0.6486    \n",
      "Epoch 9/50\n",
      "18750/18750 [==============================] - 10s - loss: 0.6226 - acc: 0.6541    - ETA: 4s - \n",
      "Epoch 10/50\n",
      "18750/18750 [==============================] - 10s - loss: 0.6188 - acc: 0.6607    \n",
      "Epoch 11/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6150 - acc: 0.6626     - ETA: 1s - loss: \n",
      "Epoch 12/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6133 - acc: 0.6619     - ETA: 4s - loss:  - ETA: 3s - loss: 0. - ETA: 1\n",
      "Epoch 13/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6061 - acc: 0.6699     \n",
      "Epoch 14/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6051 - acc: 0.6716     - ETA: 3s - loss: 0.60\n",
      "Epoch 15/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.6011 - acc: 0.6765     \n",
      "Epoch 16/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5990 - acc: 0.6772     \n",
      "Epoch 17/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5945 - acc: 0.6833     \n",
      "Epoch 18/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5928 - acc: 0.6820     \n",
      "Epoch 19/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5883 - acc: 0.6867     - ETA: 1s - loss: 0\n",
      "Epoch 20/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5861 - acc: 0.6925     \n",
      "Epoch 21/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5823 - acc: 0.6934     - ETA: 4s - l\n",
      "Epoch 22/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5814 - acc: 0.6932     \n",
      "Epoch 23/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5741 - acc: 0.7019     \n",
      "Epoch 24/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5774 - acc: 0.6987     \n",
      "Epoch 25/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5693 - acc: 0.7017     \n",
      "Epoch 26/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5646 - acc: 0.7087     \n",
      "Epoch 27/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5674 - acc: 0.7051     \n",
      "Epoch 28/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5591 - acc: 0.7148     \n",
      "Epoch 29/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5578 - acc: 0.7169     \n",
      "Epoch 30/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5574 - acc: 0.7144     \n",
      "Epoch 31/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5499 - acc: 0.7213     \n",
      "Epoch 32/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5457 - acc: 0.7248     \n",
      "Epoch 33/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5448 - acc: 0.7253     \n",
      "Epoch 34/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5414 - acc: 0.7241     \n",
      "Epoch 35/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5422 - acc: 0.7259     \n",
      "Epoch 36/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5374 - acc: 0.7290     - ETA: 3s - loss: 0.5356 \n",
      "Epoch 37/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5333 - acc: 0.7314     \n",
      "Epoch 38/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5302 - acc: 0.7375     \n",
      "Epoch 39/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5239 - acc: 0.7406     - ETA: 4s - loss: 0. - ETA: 3s - loss: 0.5\n",
      "Epoch 40/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5248 - acc: 0.7381     \n",
      "Epoch 41/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5174 - acc: 0.7486     \n",
      "Epoch 42/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5097 - acc: 0.7534     \n",
      "Epoch 43/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5121 - acc: 0.7454     -  - ETA: 0s - loss: 0.5112 - acc\n",
      "Epoch 44/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5122 - acc: 0.7480     \n",
      "Epoch 45/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5091 - acc: 0.7510     \n",
      "Epoch 46/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5026 - acc: 0.7580     \n",
      "Epoch 47/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.5001 - acc: 0.7598     - ETA: 1s - loss: 0.4969 - - ETA: 0s - loss: 0.4962 \n",
      "Epoch 48/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.4923 - acc: 0.7653     - ETA: 1s - loss: 0.4936 - acc: 0.7 - ETA: 1s - l\n",
      "Epoch 49/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.4912 - acc: 0.7674     \n",
      "Epoch 50/50\n",
      "18750/18750 [==============================] - 9s - loss: 0.4894 - acc: 0.7635     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f506aa17b70>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using SGD\n",
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "model.fit(trainData, trainLabels, nb_epoch=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating on testing set...\n",
      "6016/6250 [===========================>..] - ETA: 0s[INFO] loss=0.5990, accuracy: 68.1920%\n"
     ]
    }
   ],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you wanna save model in file, you'll need to install h5py library\n",
    "# But after this you'll need reboot you jupyter. In order to avoid it,\n",
    "# you have to just reload your keras.model (just uncomment 3 lines of \n",
    "# code below). And only after this you can save model correct.\n",
    "# Of course, if you installed h5py earlier, you don't need to uncomment\n",
    "# this code.\n",
    "\n",
    "# import keras\n",
    "# from importlib import reload\n",
    "# reload(keras.models)\n",
    "\n",
    "# save model in file\n",
    "model.save(\"cats_vs_dogs_model.h5\")\n",
    "\n",
    "\n",
    "# returns a compiled model\n",
    "#model = load_model('cats_vs_dogs_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
